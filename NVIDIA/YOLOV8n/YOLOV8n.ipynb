{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19594d8c",
   "metadata": {},
   "source": [
    "# YOLOV8n Testing Base Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu129\n",
      "Requirement already satisfied: torch in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (2.8.0+cu129)\n",
      "Requirement already satisfied: torchvision in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (0.23.0+cu129)\n",
      "Requirement already satisfied: torchaudio in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (2.8.0+cu129)\n",
      "Requirement already satisfied: filelock in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ultralytics in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (8.3.233)\n",
      "Requirement already satisfied: pandas in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: psutil in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (7.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: tqdm in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (2.8.0+cu129)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (0.23.0+cu129)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (1.35.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: colorama in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.35.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programming\\conference paper\\nvidia\\yolov8n\\.venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch (CUDA 12.9) + deps\n",
    "\n",
    "# Upgrade pip first\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# Install PyTorch with CUDA 12.9 (adjust if your setup uses a different CUDA build)\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129\n",
    "%pip install ultralytics pandas psutil matplotlib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcfc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch & GPU Status ===\n",
      "Torch Version : 2.8.0+cu129\n",
      "CUDA available: YES\n",
      "GPU Name      : NVIDIA GeForce RTX 5060 Ti\n",
      "Compute Cap   : (12, 0)\n",
      "CUDA Version  : 12.9\n",
      "\n",
      "=== Benchmark Configuration ===\n",
      "ROOT Dir         : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\n",
      "Runs Dir         : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\n",
      "Data Root        : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\n",
      "Planned YAML     : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\coco5k.yaml)\n",
      "Experiment Name  : yolov8n_coco5k_pilot\n",
      "Epochs (Pilot)   : 30\n",
      "Image Size       : 512\n",
      "Batch Size       : 16\n",
      "Workers          : 4\n",
      "Seed             : 55\n",
      "Device           : cuda\n",
      "Start Time       : 2025-12-03 16:59:13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=== PyTorch & GPU Status ===\")\n",
    "print(f\"Torch Version : {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA available: YES\")\n",
    "    print(f\"GPU Name      : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Compute Cap   : {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"CUDA Version  : {torch.version.cuda}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA available: NO (running on CPU)\")\n",
    "    print(\" This benchmark is intended to run on GPU.\")\n",
    "\n",
    "ROOT = Path(r\"C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOv8n\").resolve()\n",
    "RUNS_DIR = ROOT / \"runs\"\n",
    "DATA_ROOT = ROOT / \"data\" / \"coco5k\"   # where we'll store the 5k COCO subset\n",
    "YAML_PATH = DATA_ROOT / \"coco5k.yaml\"  # will be CREATED in Code Cell 3\n",
    "\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXPERIMENT_NAME = \"yolov8n_coco5k_pilot\"\n",
    "MODEL_WEIGHTS = \"yolov8n.pt\"   # base Ultralytics model\n",
    "\n",
    "EPOCHS_PILOT = 30\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "SEED = 55\n",
    "\n",
    "def set_seed(seed: int = 55):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "print(\"\\n=== Benchmark Configuration ===\")\n",
    "print(f\"ROOT Dir         : {ROOT}\")\n",
    "print(f\"Runs Dir         : {RUNS_DIR}\")\n",
    "print(f\"Data Root        : {DATA_ROOT}\")\n",
    "print(f\"Planned YAML     : {YAML_PATH})\")\n",
    "print(f\"Experiment Name  : {EXPERIMENT_NAME}\")\n",
    "print(f\"Epochs (Pilot)   : {EPOCHS_PILOT}\")\n",
    "print(f\"Image Size       : {IMG_SIZE}\")\n",
    "print(f\"Batch Size       : {BATCH_SIZE}\")\n",
    "print(f\"Workers          : {NUM_WORKERS}\")\n",
    "print(f\"Seed             : {SEED}\")\n",
    "print(f\"Device           : {device}\")\n",
    "print(f\"Start Time       : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3272ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COCO 2017 val (5k) – Download & Extract ===\n",
      "DATA_ROOT : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\n",
      "\n",
      "[1/4] val2017.zip already exists, skipping download.\n",
      "\n",
      "[2/4] annotations_trainval2017.zip already exists, skipping download.\n",
      "\n",
      "[3/4] val2017 directory already exists, skipping extraction.\n",
      "\n",
      "[4/4] annotations directory already exists, skipping extraction.\n",
      "\n",
      "Done. You now have:\n",
      "- Images     : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\val2017\n",
      "- Annotations: C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\annotations\n"
     ]
    }
   ],
   "source": [
    "# Uses official COCO 2017 val set (~5,000 images)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "print(\"=== COCO 2017 val (5k) – Download & Extract ===\")\n",
    "print(f\"DATA_ROOT : {DATA_ROOT}\")\n",
    "\n",
    "images_zip_path = DATA_ROOT / \"val2017.zip\"\n",
    "ann_zip_path    = DATA_ROOT / \"annotations_trainval2017.zip\"\n",
    "\n",
    "images_dir      = DATA_ROOT / \"val2017\"        # will contain 5000 images\n",
    "ann_dir         = DATA_ROOT / \"annotations\"    # will contain instances_val2017.json\n",
    "\n",
    "images_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "ann_url    = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not images_zip_path.exists():\n",
    "    print(\"\\n[1/4] Downloading COCO val2017 images (~1 GB)...\")\n",
    "    print(f\"From: {images_url}\")\n",
    "    print(f\"To  : {images_zip_path}\")\n",
    "    urlretrieve(images_url, images_zip_path)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"\\n[1/4] val2017.zip already exists, skipping download.\")\n",
    "\n",
    "if not ann_zip_path.exists():\n",
    "    print(\"\\n[2/4] Downloading COCO annotations (~250 MB)...\")\n",
    "    print(f\"From: {ann_url}\")\n",
    "    print(f\"To  : {ann_zip_path}\")\n",
    "    urlretrieve(ann_url, ann_zip_path)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"\\n[2/4] annotations_trainval2017.zip already exists, skipping download.\")\n",
    "\n",
    "if not images_dir.exists():\n",
    "    print(\"\\n[3/4] Extracting val2017.zip...\")\n",
    "    with zipfile.ZipFile(images_zip_path, 'r') as zf:\n",
    "        zf.extractall(DATA_ROOT)\n",
    "    print(f\"Extraction complete. Images in: {images_dir}\")\n",
    "else:\n",
    "    print(\"\\n[3/4] val2017 directory already exists, skipping extraction.\")\n",
    "\n",
    "if not ann_dir.exists():\n",
    "    print(\"\\n[4/4] Extracting annotations_trainval2017.zip...\")\n",
    "    with zipfile.ZipFile(ann_zip_path, 'r') as zf:\n",
    "        zf.extractall(DATA_ROOT)  # creates 'annotations' folder by default\n",
    "    print(f\"Extraction complete. Annotations in: {ann_dir}\")\n",
    "else:\n",
    "    print(\"\\n[4/4] annotations directory already exists, skipping extraction.\")\n",
    "\n",
    "print(\"\\nDone. You now have:\")\n",
    "print(f\"- Images     : {images_dir}\")\n",
    "print(f\"- Annotations: {ann_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COCO 5k → YOLO-format Conversion ===\n",
      "DATA_ROOT : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\n",
      "YAML_PATH : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\coco5k.yaml\n",
      "Detected existing YOLO-style dataset and YAML. Skipping conversion.\n",
      "\n",
      "Conversion step complete.\n",
      "- Images/train : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\images\\train2017\n",
      "- Images/val   : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\images\\val2017\n",
      "- Labels/train : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\labels\\train2017\n",
      "- Labels/val   : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\labels\\val2017\n",
      "- YAML         : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\coco5k.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== COCO 5k → YOLO-format Conversion ===\")\n",
    "print(f\"DATA_ROOT : {DATA_ROOT}\")\n",
    "print(f\"YAML_PATH : {YAML_PATH}\")\n",
    "\n",
    "images_dir = DATA_ROOT / \"val2017\"\n",
    "ann_dir = DATA_ROOT / \"annotations\"\n",
    "ann_file = ann_dir / \"instances_val2017.json\"\n",
    "\n",
    "images_root = DATA_ROOT / \"images\"\n",
    "labels_root = DATA_ROOT / \"labels\"\n",
    "\n",
    "images_train_dir = images_root / \"train2017\"\n",
    "images_val_dir   = images_root / \"val2017\"\n",
    "labels_train_dir = labels_root / \"train2017\"\n",
    "labels_val_dir   = labels_root / \"val2017\"\n",
    "\n",
    "if YAML_PATH.exists() and labels_train_dir.exists() and any(labels_train_dir.glob(\"*.txt\")):\n",
    "    print(\"Detected existing YOLO-style dataset and YAML. Skipping conversion.\")\n",
    "else:\n",
    "    # Create directories\n",
    "    images_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    images_val_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not ann_file.exists():\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {ann_file}\")\n",
    "\n",
    "    print(\"\\n[1/5] Loading COCO annotations...\")\n",
    "    with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    images_info = coco[\"images\"]\n",
    "    annotations = coco[\"annotations\"]\n",
    "    categories  = coco[\"categories\"]\n",
    "\n",
    "    print(f\"Total images in val2017: {len(images_info)}\")\n",
    "    print(f\"Total annotations      : {len(annotations)}\")\n",
    "    print(f\"Total categories       : {len(categories)}\")\n",
    "\n",
    "    imgid_to_info = {img[\"id\"]: img for img in images_info}\n",
    "\n",
    "    imgid_to_anns = {}\n",
    "    for ann in annotations:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        imgid_to_anns.setdefault(img_id, []).append(ann)\n",
    "\n",
    "    catid_to_idx = {}\n",
    "    cat_names = []\n",
    "    for idx, cat in enumerate(sorted(categories, key=lambda c: c[\"id\"])):\n",
    "        catid_to_idx[cat[\"id\"]] = idx\n",
    "        cat_names.append(cat[\"name\"])\n",
    "\n",
    "    print(\"\\n[2/5] Creating 80/20 train/val split...\")\n",
    "    # Sort images by file_name for deterministic behavior\n",
    "    sorted_imgs = sorted(images_info, key=lambda x: x[\"file_name\"])\n",
    "    n_total = len(sorted_imgs)\n",
    "    n_train = int(0.8 * n_total)\n",
    "    n_val = n_total - n_train\n",
    "\n",
    "    train_imgs = sorted_imgs[:n_train]\n",
    "    val_imgs   = sorted_imgs[n_train:]\n",
    "\n",
    "    print(f\"Train images: {len(train_imgs)}\")\n",
    "    print(f\"Val images  : {len(val_imgs)}\")\n",
    "\n",
    "    def write_yolo_labels(img, anns, target_label_dir: Path):\n",
    "        \"\"\"Write YOLO-format labels for one image.\"\"\"\n",
    "        img_w = img[\"width\"]\n",
    "        img_h = img[\"height\"]\n",
    "        stem = Path(img[\"file_name\"]).stem\n",
    "        label_path = target_label_dir / f\"{stem}.txt\"\n",
    "\n",
    "        lines = []\n",
    "        if anns:\n",
    "            for ann in anns:\n",
    "                cat_id = ann[\"category_id\"]\n",
    "                if cat_id not in catid_to_idx:\n",
    "                    continue\n",
    "                cls_idx = catid_to_idx[cat_id]\n",
    "\n",
    "                x_min, y_min, w, h = ann[\"bbox\"]\n",
    "                x_center = x_min + w / 2.0\n",
    "                y_center = y_min + h / 2.0\n",
    "\n",
    "                x_rel = x_center / img_w\n",
    "                y_rel = y_center / img_h\n",
    "                w_rel = w / img_w\n",
    "                h_rel = h / img_h\n",
    "\n",
    "                x_rel = max(0.0, min(1.0, x_rel))\n",
    "                y_rel = max(0.0, min(1.0, y_rel))\n",
    "                w_rel = max(0.0, min(1.0, w_rel))\n",
    "                h_rel = max(0.0, min(1.0, h_rel))\n",
    "\n",
    "                lines.append(f\"{cls_idx} {x_rel:.6f} {y_rel:.6f} {w_rel:.6f} {h_rel:.6f}\")\n",
    "\n",
    "        with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            if lines:\n",
    "                f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(\"\\n[3/5] Moving images and generating YOLO labels (this may take a bit)...\")\n",
    "\n",
    "    def process_split(split_name, img_list, images_src_dir, images_dst_dir, labels_dst_dir):\n",
    "        print(f\"\\n   Processing {split_name} split...\")\n",
    "        for img in img_list:\n",
    "            file_name = img[\"file_name\"]\n",
    "            src_img = images_src_dir / file_name\n",
    "            dst_img = images_dst_dir / file_name\n",
    "\n",
    "            if not dst_img.exists():\n",
    "\n",
    "                shutil.copy2(src_img, dst_img)\n",
    "\n",
    "            img_anns = imgid_to_anns.get(img[\"id\"], [])\n",
    "            write_yolo_labels(img, img_anns, labels_dst_dir)\n",
    "\n",
    "    process_split(\"train\", train_imgs, images_dir, images_train_dir, labels_train_dir)\n",
    "    process_split(\"val\",   val_imgs,   images_dir, images_val_dir,   labels_val_dir)\n",
    "\n",
    "    print(\"\\n[4/5] Finished creating YOLO images/labels for train and val splits.\")\n",
    "    print(\"\\n[5/5] Creating coco5k.yaml...\")\n",
    "\n",
    "    yaml_text = f\"\"\"# COCO 5k subset (val2017) converted to YOLO format\n",
    "# path is the root that contains 'images' and 'labels' directories\n",
    "path: {DATA_ROOT.as_posix()}\n",
    "\n",
    "train: images/train2017\n",
    "val: images/val2017\n",
    "\n",
    "nc: {len(cat_names)}\n",
    "names:\n",
    "\"\"\"\n",
    "\n",
    "    for idx, name in enumerate(cat_names):\n",
    "        yaml_text += f\"  {idx}: {name}\\n\"\n",
    "\n",
    "    with open(YAML_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(yaml_text)\n",
    "\n",
    "    print(f\"YAML created at: {YAML_PATH}\")\n",
    "\n",
    "print(\"\\nConversion step complete.\")\n",
    "print(f\"- Images/train : {images_train_dir}\")\n",
    "print(f\"- Images/val   : {images_val_dir}\")\n",
    "print(f\"- Labels/train : {labels_train_dir}\")\n",
    "print(f\"- Labels/val   : {labels_val_dir}\")\n",
    "print(f\"- YAML         : {YAML_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YOLOv8n – COCO 5k Pilot Training ===\n",
      "Using YAML       : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\coco5k.yaml\n",
      "Experiment Name  : yolov8n_coco5k_pilot\n",
      "Epochs (Pilot)   : 30\n",
      "Image Size       : 512\n",
      "Batch Size       : 16\n",
      "Workers          : 4\n",
      "Device           : cuda\n",
      "Detected train images: 4000\n",
      "New https://pypi.org/project/ultralytics/8.3.234 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.233  Python-3.10.11 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 5060 Ti, 16311MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\coco5k.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov8n_coco5k_pilot8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 254.8154.0 MB/s, size: 120.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\labels\\train2017.cache... 4000 images, 37 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4000/4000 8.0Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 260.596.3 MB/s, size: 132.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\data\\coco5k\\labels\\val2017.cache... 1000 images, 11 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 2.0Mit/s 0.0s\n",
      "Plotting labels to C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      1.52G      1.193      1.376       1.19        133        512: 100% ━━━━━━━━━━━━ 250/250 11.8it/s 21.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.1it/s 4.5s0.1s\n",
      "                   all       1000       7293      0.584      0.439      0.467      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      2.09G      1.196      1.393      1.197        103        512: 100% ━━━━━━━━━━━━ 250/250 12.5it/s 20.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.5it/s 4.2s0.1s\n",
      "                   all       1000       7293      0.602      0.409      0.458      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      2.11G      1.207      1.393      1.198        122        512: 100% ━━━━━━━━━━━━ 250/250 12.8it/s 19.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.9it/s 4.0s0.1s\n",
      "                   all       1000       7293      0.552      0.413      0.434        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      2.11G       1.21      1.385      1.204        106        512: 100% ━━━━━━━━━━━━ 250/250 13.2it/s 18.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.6it/s 4.2s0.1s\n",
      "                   all       1000       7293      0.574      0.407      0.427      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      2.11G      1.202       1.36      1.199        160        512: 100% ━━━━━━━━━━━━ 250/250 12.6it/s 19.8s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.8it/s 4.1s0.1s\n",
      "                   all       1000       7293      0.549      0.401      0.425      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      2.13G        1.2      1.329      1.193         97        512: 100% ━━━━━━━━━━━━ 250/250 12.2it/s 20.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.5s0.1s\n",
      "                   all       1000       7293      0.604       0.39       0.43      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      2.15G      1.191      1.311       1.19         80        512: 100% ━━━━━━━━━━━━ 250/250 12.5it/s 20.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.7it/s 4.8s0.1s\n",
      "                   all       1000       7293      0.559      0.402      0.428      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30      2.16G      1.179      1.292      1.184         87        512: 100% ━━━━━━━━━━━━ 250/250 12.9it/s 19.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.0it/s 4.0s0.1s\n",
      "                   all       1000       7293       0.56      0.406      0.433      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      2.16G      1.167      1.267      1.175         81        512: 100% ━━━━━━━━━━━━ 250/250 12.9it/s 19.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.6s0.1s\n",
      "                   all       1000       7293      0.539      0.403      0.423      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      2.16G      1.157      1.246      1.169        101        512: 100% ━━━━━━━━━━━━ 250/250 12.4it/s 20.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.1it/s 4.5s0.2s\n",
      "                   all       1000       7293      0.542      0.406      0.431      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      2.16G       1.16      1.238      1.168        132        512: 100% ━━━━━━━━━━━━ 250/250 12.3it/s 20.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.0it/s 4.0s0.1s\n",
      "                   all       1000       7293      0.523      0.418      0.428      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      2.16G       1.15      1.204      1.161        132        512: 100% ━━━━━━━━━━━━ 250/250 12.5it/s 20.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.1it/s 4.5s0.1s\n",
      "                   all       1000       7293      0.553        0.4      0.432      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      2.17G       1.14      1.183      1.157         83        512: 100% ━━━━━━━━━━━━ 250/250 12.7it/s 19.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.8it/s 4.1s0.1s\n",
      "                   all       1000       7293      0.563      0.402       0.43      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30      2.17G       1.14       1.18      1.158        139        512: 100% ━━━━━━━━━━━━ 250/250 13.0it/s 19.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.9it/s 4.0s0.1s\n",
      "                   all       1000       7293      0.549      0.402      0.428      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      2.17G      1.132      1.161      1.149        163        512: 100% ━━━━━━━━━━━━ 250/250 13.0it/s 19.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.9it/s 4.1s0.1s\n",
      "                   all       1000       7293      0.566        0.4      0.431      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      2.17G      1.126      1.146      1.149        135        512: 100% ━━━━━━━━━━━━ 250/250 12.5it/s 20.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.7it/s 4.1s0.1s\n",
      "                   all       1000       7293      0.538      0.404      0.424      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      2.17G       1.12      1.128      1.143         92        512: 100% ━━━━━━━━━━━━ 250/250 13.2it/s 18.9s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 8.1it/s 3.9s0.1s\n",
      "                   all       1000       7293      0.557      0.406      0.427      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      2.17G      1.122      1.121      1.136        115        512: 100% ━━━━━━━━━━━━ 250/250 12.5it/s 20.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.8it/s 4.1s0.1s\n",
      "                   all       1000       7293      0.544      0.405      0.426      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      2.17G      1.116      1.111      1.139        113        512: 100% ━━━━━━━━━━━━ 250/250 12.3it/s 20.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.6s0.1s\n",
      "                   all       1000       7293      0.522      0.411      0.428      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      2.17G      1.102      1.098      1.132        134        512: 100% ━━━━━━━━━━━━ 250/250 12.2it/s 20.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.5it/s 4.3s0.1s\n",
      "                   all       1000       7293      0.557      0.408      0.427      0.293\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      2.17G      1.101      1.089      1.128         90        512: 100% ━━━━━━━━━━━━ 250/250 10.8it/s 23.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.6it/s 4.2s0.1s\n",
      "                   all       1000       7293      0.566      0.404      0.428      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      2.17G      1.098      1.078      1.127        140        512: 100% ━━━━━━━━━━━━ 250/250 11.3it/s 22.0s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.9it/s 4.6s0.1s\n",
      "                   all       1000       7293      0.559      0.404      0.428      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      2.17G       1.09      1.067      1.122        105        512: 100% ━━━━━━━━━━━━ 250/250 11.8it/s 21.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.6s0.1s\n",
      "                   all       1000       7293       0.58      0.394      0.429      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      2.17G      1.084      1.057      1.118         54        512: 100% ━━━━━━━━━━━━ 250/250 11.8it/s 21.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.5s0.1s\n",
      "                   all       1000       7293      0.577       0.39      0.425      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      2.17G      1.088      1.049      1.121        126        512: 100% ━━━━━━━━━━━━ 250/250 11.6it/s 21.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.6s0.1s\n",
      "                   all       1000       7293      0.576      0.388      0.425      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      2.17G      1.081       1.04      1.117         94        512: 100% ━━━━━━━━━━━━ 250/250 11.2it/s 22.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.9it/s 4.6s0.1s\n",
      "                   all       1000       7293      0.576      0.389      0.425      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      2.17G      1.077      1.026      1.112        112        512: 100% ━━━━━━━━━━━━ 250/250 11.6it/s 21.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 7.0it/s 4.5s0.1s\n",
      "                   all       1000       7293      0.566      0.395      0.427      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      2.17G      1.077      1.028      1.111         74        512: 100% ━━━━━━━━━━━━ 250/250 11.3it/s 22.1s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.7it/s 4.7s0.1s\n",
      "                   all       1000       7293      0.567      0.396      0.429      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      2.17G      1.073      1.024      1.108        113        512: 100% ━━━━━━━━━━━━ 250/250 11.5it/s 21.7s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.8it/s 4.7s0.1s\n",
      "                   all       1000       7293      0.567       0.39      0.427      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      2.17G      1.065      1.014      1.107        152        512: 100% ━━━━━━━━━━━━ 250/250 11.7it/s 21.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 6.5it/s 4.9s0.2s\n",
      "                   all       1000       7293      0.582      0.386      0.429      0.295\n",
      "\n",
      "30 epochs completed in 0.212 hours.\n",
      "Optimizer stripped from C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\\weights\\best.pt...\n",
      "Ultralytics 8.3.233  Python-3.10.11 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 5060 Ti, 16311MiB)\n",
      "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 32/32 5.6it/s 5.7s0.2s\n",
      "                   all       1000       7293      0.585      0.439      0.467      0.329\n",
      "                person        528       2016      0.756      0.657      0.722      0.486\n",
      "               bicycle         21         54      0.587      0.407      0.443      0.264\n",
      "                   car        107        383       0.56      0.368      0.385      0.232\n",
      "            motorcycle         30         88      0.638      0.521      0.631      0.393\n",
      "              airplane         27         39       0.82      0.744       0.81      0.567\n",
      "                   bus         34         47      0.589      0.638      0.655       0.58\n",
      "                 train         39         46       0.72      0.696       0.79      0.638\n",
      "                 truck         54        107      0.612      0.299       0.36      0.226\n",
      "                  boat         30        118      0.494      0.297      0.303      0.156\n",
      "         traffic light         46        136      0.674      0.272      0.341      0.183\n",
      "          fire hydrant         15         16      0.625      0.562      0.551      0.442\n",
      "             stop sign         11         14      0.684       0.62      0.641      0.594\n",
      "         parking meter          8          9      0.353      0.333      0.259      0.238\n",
      "                 bench         37         52      0.567      0.231      0.265      0.195\n",
      "                  bird         28         87      0.772      0.391      0.471       0.31\n",
      "                   cat         33         37       0.75      0.892      0.882      0.762\n",
      "                   dog         35         41      0.738      0.659      0.721      0.582\n",
      "                 horse         20         37      0.735      0.784      0.812      0.569\n",
      "                 sheep         14         79      0.562      0.646      0.597      0.385\n",
      "                   cow         14         46      0.689      0.625      0.669      0.472\n",
      "              elephant         14         37       0.63      0.703      0.766      0.557\n",
      "                  bear         10         13      0.595      0.923      0.876      0.771\n",
      "                 zebra         20         70      0.799        0.8      0.872      0.683\n",
      "               giraffe         18         47      0.765      0.723      0.842       0.59\n",
      "              backpack         35         61      0.308      0.103      0.169     0.0904\n",
      "              umbrella         36        109      0.684      0.385      0.458      0.303\n",
      "               handbag         62        104       0.51      0.106      0.166     0.0801\n",
      "                   tie         30         47      0.554      0.291      0.342      0.208\n",
      "              suitcase         12         58      0.549      0.466      0.476      0.305\n",
      "               frisbee         15         18      0.719      0.427      0.641      0.448\n",
      "                  skis         24         73      0.549      0.192      0.289      0.146\n",
      "             snowboard          9         21      0.605      0.238      0.239      0.149\n",
      "           sports ball         24         37      0.767      0.297      0.366      0.239\n",
      "                  kite         22         80      0.658      0.575      0.615      0.396\n",
      "          baseball bat         16         17      0.318      0.353      0.233      0.141\n",
      "        baseball glove         23         34       0.59      0.441      0.458       0.25\n",
      "            skateboard         24         42      0.811      0.476      0.534      0.385\n",
      "             surfboard         32         65      0.486        0.4      0.376       0.21\n",
      "         tennis racket         21         28      0.529      0.393      0.479      0.293\n",
      "                bottle         83        211      0.666      0.384      0.435       0.28\n",
      "            wine glass         20         62      0.539      0.226      0.255      0.182\n",
      "                   cup         76        199      0.485      0.364      0.392       0.25\n",
      "                  fork         27         39      0.627      0.256      0.317      0.181\n",
      "                 knife         28         53      0.283      0.097      0.136     0.0844\n",
      "                 spoon         33         51      0.379      0.137      0.177      0.118\n",
      "                  bowl         72        139      0.527      0.361       0.42      0.275\n",
      "                banana         25        110      0.473        0.4       0.37      0.228\n",
      "                 apple         18         76      0.451      0.289      0.268      0.203\n",
      "              sandwich         14         20       0.57       0.75      0.732      0.619\n",
      "                orange         17         56      0.287      0.411      0.246      0.145\n",
      "              broccoli         12         62      0.468       0.34      0.405       0.25\n",
      "                carrot         10         58       0.25      0.345      0.218      0.154\n",
      "               hot dog         11         27      0.432      0.333       0.32      0.229\n",
      "                 pizza         24         39      0.681      0.603      0.665        0.5\n",
      "                 donut         13         62       0.29      0.419      0.301      0.219\n",
      "                  cake         19         48      0.507      0.271      0.313      0.231\n",
      "                 chair        120        381      0.652      0.323      0.392      0.239\n",
      "                 couch         54         70      0.608      0.486      0.565      0.436\n",
      "          potted plant         42         79      0.487      0.277      0.297      0.192\n",
      "                   bed         28         31      0.542      0.535      0.531      0.397\n",
      "          dining table         95        128      0.541      0.383      0.388      0.266\n",
      "                toilet         26         28        0.6      0.749      0.735      0.578\n",
      "                    tv         46         67      0.668      0.569      0.597      0.477\n",
      "                laptop         36         45      0.621      0.733      0.755       0.65\n",
      "                 mouse         22         23       0.62      0.609      0.653      0.458\n",
      "                remote         38         79      0.355       0.19      0.221      0.118\n",
      "              keyboard         20         27      0.334      0.593      0.586      0.411\n",
      "            cell phone         37         43      0.752      0.564      0.621      0.405\n",
      "             microwave         14         14      0.673      0.571      0.543      0.287\n",
      "                  oven         25         30      0.383      0.433      0.398      0.221\n",
      "               toaster          1          1          1          0      0.249      0.149\n",
      "                  sink         40         53      0.373      0.302      0.363      0.208\n",
      "          refrigerator         21         23      0.624      0.649      0.643      0.491\n",
      "                  book         50        258      0.361      0.124      0.159     0.0712\n",
      "                 clock         37         54      0.718      0.519      0.575      0.435\n",
      "                  vase         39         68      0.557      0.498      0.489      0.305\n",
      "              scissors          4          5          1      0.588      0.607      0.486\n",
      "            teddy bear         17         32      0.472      0.375      0.315      0.207\n",
      "            hair drier          3          3          1          0          0          0\n",
      "            toothbrush         13         26      0.578      0.115      0.209       0.13\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\u001b[0m\n",
      "\n",
      "=== Pilot Training Finished ===\n",
      "Total time (s)     : 798.47\n",
      "Avg time / epoch   : 26.616 s\n",
      "Approx. throughput : 150.29 images/s\n",
      "\n",
      "Run directory      : C:\\Programming\\CONFERENCE PAPER\\NVIDIA\\YOLOV8n\\runs\\yolov8n_coco5k_pilot8\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "print(\"=== YOLOv8n – COCO 5k Pilot Training ===\")\n",
    "\n",
    "if not YAML_PATH.exists():\n",
    "    raise FileNotFoundError(f\"YAML file not found: {YAML_PATH}\")\n",
    "\n",
    "print(f\"Using YAML       : {YAML_PATH}\")\n",
    "print(f\"Experiment Name  : {EXPERIMENT_NAME}\")\n",
    "print(f\"Epochs (Pilot)   : {EPOCHS_PILOT}\")\n",
    "print(f\"Image Size       : {IMG_SIZE}\")\n",
    "print(f\"Batch Size       : {BATCH_SIZE}\")\n",
    "print(f\"Workers          : {NUM_WORKERS}\")\n",
    "print(f\"Device           : {device}\")\n",
    "\n",
    "train_images_dir = DATA_ROOT / \"images\" / \"train2017\"\n",
    "if not train_images_dir.exists():\n",
    "    raise FileNotFoundError(f\"Train images dir not found: {train_images_dir}\")\n",
    "\n",
    "train_image_count = sum(\n",
    "    1 for p in train_images_dir.glob(\"*.*\")\n",
    "    if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
    ")\n",
    "print(f\"Detected train images: {train_image_count}\")\n",
    "\n",
    "model = YOLO(MODEL_WEIGHTS)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.train(\n",
    "    data=str(YAML_PATH),\n",
    "    epochs=EPOCHS_PILOT,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    workers=NUM_WORKERS,\n",
    "    mosaic=0.0, \n",
    "    project=str(RUNS_DIR),\n",
    "    name=EXPERIMENT_NAME,\n",
    "    device=0,   \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time_sec = end_time - start_time\n",
    "avg_epoch_time = total_time_sec / EPOCHS_PILOT\n",
    "\n",
    "print(\"\\n=== Pilot Training Finished ===\")\n",
    "print(f\"Total time (s)     : {total_time_sec:.2f}\")\n",
    "print(f\"Avg time / epoch   : {avg_epoch_time:.3f} s\")\n",
    "\n",
    "if train_image_count > 0:\n",
    "    total_images_seen = train_image_count * EPOCHS_PILOT\n",
    "    throughput = total_images_seen / total_time_sec\n",
    "    print(f\"Approx. throughput : {throughput:.2f} images/s\")\n",
    "else:\n",
    "    print(\"Approx. throughput : N/A (train_image_count = 0)\")\n",
    "\n",
    "if hasattr(results, \"save_dir\"):\n",
    "    print(f\"\\nRun directory      : {results.save_dir}\")\n",
    "else:\n",
    "    print(\"\\nCheck runs folder  :\", RUNS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
